{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhyeonlee0827/2023-2-AI-Study/blob/main/Transformer_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFFmt1G9yMM_"
      },
      "source": [
        "# NLP 2 ê³¼ì œ\n",
        "> ì¸ê³µì§€ëŠ¥ ìŠ¤í„°ë”” ì¼ê³± ë²ˆì§¸ ê³¼ì œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ê°•ì˜ë¥¼ ë“¤ìœ¼ë©´ì„œ ë°°ìš´ ë‹¤ì–‘í•œ ì§€ì‹ë“¤ì„ ì‹¤ìŠµì„ í†µí•´ì„œ í™œìš©í•´ ë³¼ ì‹œê°„ì„ ê°€ì§ˆ ê²ƒì…ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwsLJnEXyMND"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Transformer\n",
        "\n",
        "ì•„ë˜ì˜ ìˆ˜ì‹ê³¼ ê°™ì´ ê³„ì‚°ë˜ëŠ” multi-head attentionì—ì„œ query, key, value ë²¡í„°ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ\n",
        "projection matrix $(â€¯W_{i}^{Q}, W_{i}^{K}, W_{i}^{V}â€‹â€‹â€¯)$ëŠ” head ê°„ì— sharing ëœë‹¤. <br>\n",
        "***\n",
        "$â€¯MultiHead(Q,K,V)=Concat(head_1, \\cdots, head_h)W^{O} $ (ì´ë•Œ, $W^{O}$ ëŠ” Outputì„ ë§Œë“¤ë•Œ ì‚¬ìš©ë˜ëŠ” ê°€ì¤‘ì¹˜ í–‰ë ¬)<br>\n",
        "where $head_i=Attention(QW^{Q}_{i}, KW^{K}_{i}, VW^{V}_{i})$ (ì´ë•Œ, $Q, K, V$ ëŠ” ì…ë ¥ì—ì„œ tokenizeëœ ë‹¨ì–´ë“¤ì˜ ì„ë² ë”© ë²¡í„° $Q = K = V$ )\n",
        "```python\n",
        "(1) ì˜ˆ\n",
        "(2) ì•„ë‹ˆì˜¤\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cYXp3CLyMNE"
      },
      "source": [
        "```python\n",
        "ğŸ˜‰\n",
        "# TODO : ì •ë‹µì„ ì ì–´ì£¼ì„¸ìš”\n",
        "1\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNU3T0KdyMNE"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Transformer\n",
        "```python\n",
        "Transformer ëª¨ë¸ì—ì„œ ê° ì…ë ¥ í† í°ë“¤ì´ ê°€ì§„ ìˆœì„œë¥¼ ì…ë ¥í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ê³ ë¥´ì‹œì˜¤.\n",
        "\n",
        "(1) Positional Encoding\n",
        "(2) Encoder-Decoder attention\n",
        "(3) Layer normalization\n",
        "(4) Masked decoder self-attention\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzebY-8lyMNF"
      },
      "source": [
        "```python\n",
        "ğŸ˜‰\n",
        "# TODO : ì •ë‹µì„ ì ì–´ì£¼ì„¸ìš”\n",
        "1\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp43YODayMNF"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> GPT\n",
        "```python\n",
        "GPT-1 ëª¨ë¸ì´ ì–´ë–»ê²Œ ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ íƒœìŠ¤í¬ì—ì„œ ì‚¬ìš©ë  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-r_nu_YyMNF"
      },
      "source": [
        "```python\n",
        "ğŸ˜‰\n",
        "# TODO : ì •ë‹µì„ ì ì–´ì£¼ì„¸ìš”\n",
        "Supervised fine-tuning took as few as 3 epochs for most of the downstream tasks.\n",
        "GPT-1 performed better than specifically trained supervised state-of-the-art models in 9 out of 12 tasks the models were compared on.\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn7YgSGhyMNF"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> GPT\n",
        "```python\n",
        "GPT-1 ëª¨ë¸ì˜ \"GPT\" ì•½ìëŠ” ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?\n",
        "\n",
        "(1) Generalized Pre-trained Transformer\n",
        "(2) Generative Pre-trained Transformer\n",
        "(3) Globalized Pre-processing Transformer\n",
        "(4) Gradient Propagation Technique\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr-F_vW_yMNG"
      },
      "source": [
        "```python\n",
        "ğŸ˜‰\n",
        "# TODO : ì •ë‹µì„ ì ì–´ì£¼ì„¸ìš”\n",
        "2\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gk-b7hIyMNG"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> BERT\n",
        "```python\n",
        "ë‹¤ìŒ ì¤‘ BERTì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ì˜³ì§€ ì•Šì€ ê²ƒì„ ê³ ë¥´ì‹œì˜¤.\n",
        "\n",
        "(1) í•™ìŠµ ë°ì´í„°ì—ì„œ [MASK] í† í°ì´ ì„ íƒë˜ëŠ” ë¹„ìœ¨ì´ ê·¹ë‹¨ì ìœ¼ë¡œ ì‘ì€ ê²½ìš°, ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë¹„ìš©ì´ ì¦ê°€í•œë‹¤.\n",
        "(2) Unidirectional modelë¡œ ìì—°ì–´ ìƒì„±ì— íŠ¹í™”ëœ ëª¨ë¸ì´ë‹¤.\n",
        "(3) ì…ë ¥ ì‹œí€€ìŠ¤ ì¤‘ ì¼ë¶€ ë§ˆìŠ¤í‚¹ëœ í† í°ì„ ë§ì¶”ëŠ” masked language modeling (masked LM)ì„ í†µí•´ pre-trainingì„ ìˆ˜í–‰í•˜ì˜€ë‹¤.\n",
        "(4) ì‚¬ì „í•™ìŠµì„ ìœ„í•œ [MASK] í† í°ì€ randomí•˜ê²Œ ì„ íƒëœë‹¤.\n",
        "(5) Unlabeled ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ self-supervised learningì„ ì ìš©í•˜ì—¬ ì‚¬ì „í•™ìŠµí•œ ëª¨ë¸ì´ë‹¤.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJa3t1UDyMNG"
      },
      "source": [
        "```python\n",
        "ğŸ˜‰\n",
        "# TODO : ì •ë‹µì„ ì ì–´ì£¼ì„¸ìš”\n",
        "2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJUi06fwyMNG"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì‹¤ìŠµ ]</b></font> Multi-head Attention\n",
        "```python\n",
        "ì´ë²ˆ ì‹¤ìŠµì„ í†µí•´ ë‹¤ìŒ 2ê°€ì§€ë¥¼ ì•Œì•„ë³¼ ê²ƒì…ë‹ˆë‹¤.\n",
        "1. Multi-head attention ë° self-attentionì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "2. ê° ê³¼ì •ì—ì„œ ì¼ì–´ë‚˜ëŠ” ì—°ì‚°ê³¼ input/output í˜•íƒœë¥¼ ì´í•´í•©ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulhN-MGmyMNG"
      },
      "source": [
        "```python\n",
        "ğŸ™\n",
        "ë¨¼ì € ì½”ë“œ ì‹¤í–‰ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ import í•´ë´…ì‹œë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQXUzuoGyMNH"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_3ps0DzyMNI"
      },
      "source": [
        "### ë°ì´í„° ì „ì²˜ë¦¬\n",
        "```python\n",
        "ì €ë²ˆ ì£¼ì°¨ì˜ ë°ì´í„°ì™€ ë¹„ìŠ·í•œ í˜•íƒœì…ë‹ˆë‹¤.\n",
        "ë¨¼ì € ì „ì²´ ë‹¨ì–´ ìˆ˜ì¸ vocab_sizeê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
        "pad_idëŠ” ì£¼ì–´ì§„ ë°ì´í„°ì˜ ê¸¸ì´ë¥¼ ë§ì¶°ì£¼ê¸° ìœ„í•´ íŒ¨ë”©ì„ ì§„í–‰í•˜ê²Œ ë˜ëŠ”ë° ì´ë•Œ íŒ¨ë”©ì„ ì˜ë¯¸í•˜ëŠ” í† í°ì˜ idì…ë‹ˆë‹¤.\n",
        "sample data ë³´ë©´ ìˆ«ìë¡œ ì´ë£¨ì–´ì§„ ê²ƒì„ ë³¼ ìˆ˜ ìˆëŠ”ë° ì´ëŠ” ì €í¬ê°€ êµ¬ì„±í•œ vocabì—ì„œ ëª‡ ë²ˆì§¸ ë‹¨ì–´ì¸ì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "ë”°ë¼ì„œ ë°ì´í„°ì˜ ê° ìš”ì†Œë¥¼ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì§„ ë¬¸ì¥ì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPNB5JgJyMNI"
      },
      "outputs": [],
      "source": [
        "vocab_size = 100\n",
        "pad_id = 0\n",
        "\n",
        "data = [\n",
        "  [62, 13, 47, 39, 78, 33, 56, 13, 39, 29, 44, 86, 71, 36, 18, 75],\n",
        "  [60, 96, 51, 32, 90],\n",
        "  [35, 45, 48, 65, 91, 99, 92, 10, 3, 21, 54],\n",
        "  [75, 51],\n",
        "  [66, 88, 98, 47],\n",
        "  [21, 39, 10, 64, 21],\n",
        "  [98],\n",
        "  [77, 65, 51, 77, 19, 15, 35, 19, 23, 97, 50, 46, 53, 42, 45, 91, 66, 3, 43, 10],\n",
        "  [70, 64, 98, 25, 99, 53, 4, 13, 69, 62, 66, 76, 15, 75, 45, 34],\n",
        "  [20, 64, 81, 35, 76, 85, 1, 62, 8, 45, 99, 77, 19, 43]\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFZn-yb6yMNI"
      },
      "source": [
        "```python\n",
        "ì£¼ì–´ì§„ ë°ì´í„°ì˜ ê¸¸ì´ë¥¼ ë§ì¶°ì£¼ê¸° ìœ„í•œ padding í•¨ìˆ˜ë¥¼ ë„ì…í•©ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87n2VzFSyMNI"
      },
      "outputs": [],
      "source": [
        "def padding(data):\n",
        "  max_len = len(max(data, key=len))\n",
        "  print(f\"Maximum sequence length: {max_len}\")\n",
        "\n",
        "  for i, seq in enumerate(tqdm(data)):\n",
        "    if len(seq) < max_len:\n",
        "      data[i] = seq + [pad_id] * (max_len - len(seq))\n",
        "\n",
        "  return data, max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBGPI6wayMNI"
      },
      "outputs": [],
      "source": [
        "data, max_len = padding(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42SF3HZkyMNI"
      },
      "source": [
        "```python\n",
        "ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ í™•ì¸í•´ ë³´ë©´ ì˜ íŒ¨ë”© ë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M82JFBmVyMNI"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHosi9payMNJ"
      },
      "source": [
        "### Hyperparameter ì„¸íŒ… ë° embedding\n",
        "```python\n",
        "ìœ„ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ì—¬ ì‹¤ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpQlKlmIyMNJ"
      },
      "outputs": [],
      "source": [
        "d_model = 512  # modelì˜ hidden size\n",
        "num_heads = 8  # multi-headì—ì„œì˜ headì˜ ê°œìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwkPDG7pyMNJ"
      },
      "outputs": [],
      "source": [
        "embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "# B: ë°°ì¹˜ ì‚¬ì´ì¦ˆ, L: maximum sequence length\n",
        "batch = torch.LongTensor(data)  # (B, L)\n",
        "batch_emb = embedding(batch)  # (B, L, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4mOsNAryMNJ"
      },
      "outputs": [],
      "source": [
        "print(batch_emb)\n",
        "print(batch_emb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBeaEK_eyMNJ"
      },
      "source": [
        "### Linear transformation & ì—¬ëŸ¬ headë¡œ ë‚˜ëˆ„ê¸°\n",
        "```python\n",
        "Multi-head attention ë‚´ì—ì„œ ì“°ì´ëŠ” linear transformation matrixë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "query, key, valueë¥¼ ì„œë¡œ ë‹¤ë¥¸ linear transformation matrixë¡œ í–‰ë ¬ ì—°ì‚°ì„ í†µí•´ ë§Œë“¤ì–´ ëƒ…ë‹ˆë‹¤. ë”°ë¼ì„œ ë™ì¼í•œ ë°ì´í„°(batch_emb)ë¡œë¶€í„° ì„œë¡œ ë‹¤ë¥¸ query, key, valueë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZorbczD8yMNJ"
      },
      "outputs": [],
      "source": [
        "w_q = nn.Linear(d_model, d_model)\n",
        "w_k = nn.Linear(d_model, d_model)\n",
        "w_v = nn.Linear(d_model, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eU64c_IyMNJ"
      },
      "source": [
        "```python\n",
        "output layerì—ì„œ ì‚¬ìš©ë  í–‰ë ¬ë„ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv8oAH8nyMNK"
      },
      "outputs": [],
      "source": [
        "w_0 = nn.Linear(d_model, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1boaN8myMNK"
      },
      "outputs": [],
      "source": [
        "q = w_q(batch_emb)  # (B, L, d_model)\n",
        "k = w_k(batch_emb)  # (B, L, d_model)\n",
        "v = w_v(batch_emb)  # (B, L, d_model)\n",
        "\n",
        "print(q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cP5KLeQyMNK"
      },
      "source": [
        "```python\n",
        "q, k, vë¥¼ 'num_head' ê°œì˜ ì°¨ì›ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì—¬ëŸ¬ ë²¡í„°ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
        "ì‹¤ì œ q, k, v ê°ê°ì˜ ë²¡í„° í¬ê¸°ëŠ” 512ê°€ ì•„ë‹Œ 64ì…ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38NCX05ryMNK"
      },
      "outputs": [],
      "source": [
        "batch_size = q.shape[0]\n",
        "d_k = d_model // num_heads # q, k, v ë²¡í„° ì‚¬ì´ì¦ˆ\n",
        "\n",
        "q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "\n",
        "print(q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejx-WARSyMNK"
      },
      "source": [
        "```python\n",
        "8ê°œì˜ headì— í•„ìš”í•œ q, k, vê°€ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjBEMC0yyMNK"
      },
      "outputs": [],
      "source": [
        "q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\n",
        "\n",
        "print(q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kU6r-yCyMNK"
      },
      "source": [
        "### Scaled dot-product self-attention êµ¬í˜„\n",
        "```python\n",
        "ê° headì—ì„œ ì‹¤í–‰ë˜ëŠ” self-attention ê³¼ì •ì„ ì‚´í´ë´…ì‹œë‹¤.\n",
        "\n",
        "q, k ë²¡í„°ì˜ ë‚´ì  ì—°ì‚° ì´í›„ì— d_kì˜ ì œê³±ê·¼ìœ¼ë¡œ ë‚˜ëˆ ì¤ë‹ˆë‹¤.\n",
        "ì´ëŠ” qì™€ kë¥¼ êµ¬ì„±í•˜ëŠ” ìš”ì†Œì˜ í‰ê· ê³¼ ë¶„ì‚°ì„ ë‚´ì ì˜ ê²°ê´ê°’ì— ëŒ€í•´ì„œë„ ìœ ì§€ì‹œì¼œì£¼ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´í›„ ê³„ì‚°ëœ ê° í–‰ì— ëŒ€í•´ì„œ softmax ì—°ì‚°ì„ í†µí•´ì„œ ê° ìš”ì†Œì˜ í•©ì„ 1ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.\n",
        "```\n",
        "- [Scaled Dot-Product Attention ì°¸ê³ ](https://paperswithcode.com/method/scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6cT2xHqyMNL"
      },
      "outputs": [],
      "source": [
        "attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)\n",
        "attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, L, L)\n",
        "\n",
        "print(attn_dists)\n",
        "print(attn_dists.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXkizw1fyMNL"
      },
      "source": [
        "```python\n",
        "ì´í›„ ê³„ì‚°ëœ attention ê°’ì„ vê³¼ ê³±í•˜ì—¬ ìµœì¢… ê²°ê´ê°’ì„ ì œì‹œí•©ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stLnfAmwyMNL"
      },
      "outputs": [],
      "source": [
        "attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\n",
        "\n",
        "print(attn_values.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruTnpzmdyMNL"
      },
      "source": [
        "### ê° headì˜ ê²°ê³¼ ë³‘í•©(concat)\n",
        "```python\n",
        "ê° headì˜ ê²°ê³¼ë¬¼ì„ concatí•˜ê³  ë™ì¼ ì°¨ì›(d_model)ìœ¼ë¡œ linear transformation í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œ 'd_model' ì°¨ì›ìœ¼ë¡œ linear transformation í•˜ëŠ” ì´ìœ ëŠ” transformer ëª¨ë¸ì—ì„œ ì›ë˜ì˜ ë°ì´í„°ì™€ ë”í•˜ëŠ” ì—°ì‚°(residual connection)ì´ ì¡´ì¬í•˜ì—¬ ì´ë•Œ ì°¨ì›ì„ í†µì¼í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "residual connection ì—°ì‚°ì€ ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ Self-Attention ë¸”ë¡ ì´í›„ Addì— í•´ë‹¹í•˜ëŠ” ì—°ì‚°ì…ë‹ˆë‹¤.\n",
        "\n",
        "residual connectionì€ ì•ì„  ê°•ì˜ì—ì„œ ë°°ìš´ resnetì—ì„œ ì†Œê°œëœ ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
        "```\n",
        "![residual](https://github.com/Pjunn/GDSC_mlstudy/blob/main/7%EC%A3%BC%EC%B0%A8/transformer_resideual_layer_norm.png?raw=true)\n",
        "ì´ë¯¸ì§€ ì¶œì²˜: https://jalammar.github.io/illustrated-transformer/ <br><br>\n",
        "-[What is Residual Connection?](https://paperswithcode.com/method/residual-connection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK_T826EyMNQ"
      },
      "outputs": [],
      "source": [
        "attn_values = attn_values.transpose(1, 2)  # (B, L, num_heads, d_k)\n",
        "attn_values = attn_values.contiguous().view(batch_size, -1, d_model)  # (B, L, d_model)\n",
        "\n",
        "print(attn_values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTtl73-RyMNQ"
      },
      "outputs": [],
      "source": [
        "outputs = w_0(attn_values)\n",
        "\n",
        "print(outputs)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHXDWz_ryMNQ"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ìœ„ì˜ ê³¼ì •ì„ ëª¨ë‘ í•©ì³ í•˜ë‚˜ì˜ Multi-head attention ëª¨ë“ˆì„ êµ¬í˜„í•´ ë´…ì‹œë‹¤.\n",
        "```python\n",
        "ğŸ™\n",
        "ì•„ë˜ì˜ Multi-head attention ëª¨ë“ˆì—ì„œ '#TODO'ë¥¼ ì±„ì›Œ ëª¨ë“ˆì„ ì™„ì„± ì‹œì¼œì£¼ì„¸ìš”.\n",
        "ìœ„ ì‹¤ìŠµì—ì„œ ë°°ìš´ ë‚´ìš©ì´ í° íŒíŠ¸ê°€ ë  ê±°ì˜ˆìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_k6hn7tyMNQ"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self, dim_model, num_heads):\n",
        "    super(MultiheadAttention, self).__init__()\n",
        "\n",
        "    assert dim_model % num_heads == 0\n",
        "\n",
        "    self.dim_model = dim_model\n",
        "    self.num_heads = num_heads\n",
        "    self.d_k = #TODO\n",
        "\n",
        "    # Q, K, V ë³€í™˜ì‹œì¼œì£¼ëŠ” ë ˆì´ì–´\n",
        "    self.w_q = #TODO\n",
        "    self.w_k = #TODO\n",
        "    self.w_v = #TODO\n",
        "\n",
        "    # concatëœ ì•„ì›ƒí’‹ì„ ë³€í™˜ì‹œì¼œì£¼ëŠ” ë ˆì´ì–´\n",
        "    self.w_0 = #TODO\n",
        "\n",
        "  def forward(self, query, key, value):\n",
        "\n",
        "    #TODO\n",
        "\n",
        "    attn_values = self.self_attention(q, k, v)  # (B, num_heads, L, d_k)\n",
        "\n",
        "    #TODO\n",
        "\n",
        "    output =\n",
        "\n",
        "    return outputs\n",
        "\n",
        "  def self_attention(self, q, k, v):\n",
        "    #TODO\n",
        "\n",
        "    return attn_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewyDufC9yMNR"
      },
      "outputs": [],
      "source": [
        "dim_model = 512\n",
        "num_heads = 8\n",
        "multihead_attn = MultiheadAttention(dim_model, num_heads)\n",
        "\n",
        "outputs = multihead_attn(batch_emb, batch_emb, batch_emb)  # (B, L, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HItYla5NyMNR"
      },
      "outputs": [],
      "source": [
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "if outputs.shape == batch_emb.shape:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ™ ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
